<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Structured Data Understanding — From LLMs to the Human Brain to a Biologically Inspired Implementation | Yuechun (Ethan) Gu </title> <meta name="author" content="Yuechun (Ethan) Gu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rhincodone.github.io/posts/2025-08-01-Structured/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yuechun (Ethan)</span> Gu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">ABOUT </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">BLOG </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">PUBLICATIONS </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/services/">SERVICES </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Structured Data Understanding — From LLMs to the Human Brain to a Biologically Inspired Implementation</h1> <p class="post-meta"> August 01, 2025 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2025   ·   <i class="fa-solid fa-hashtag fa-sm"></i> metrics     ·   <i class="fa-solid fa-tag fa-sm"></i> Brain_LLM_En   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="structured-data-understanding--from-llms-to-the-human-brain-to-a-biologically-inspired-implementation">Structured Data Understanding — From LLMs to the Human Brain to a Biologically Inspired Implementation</h1> <h2 id="1-problem-background">1. Problem Background</h2> <p>In risk-control scenarios, structured data (e.g. behavior sequences, social graphs, transaction tables) plays a core role in threat detection. While large language models (LLMs) excel at understanding text and images, they still face limitations in making sense of and reasoning over structured data:</p> <ul> <li> <strong>Difficulty aligning structure with semantics</strong>: Graph or temporal structures are hard to map into the language-based semantic space</li> <li> <strong>Input length and efficiency bottlenecks</strong>: Linearizing large-scale structured data easily exceeds the input limits of LLMs</li> <li> <strong>Weak multi-step reasoning ability</strong>: Complex relationships in structured data are difficult for LLMs to handle using chain-of-thought</li> <li> <strong>Immature fusion of heterogeneous sources</strong>: Combining graph, sequence, and tabular data into a unified representation remains an open challenge</li> </ul> <p>Models like GraphGPT, GraphRAG, and StructGPT have begun to explore how to integrate structural information with language, but most still focus on a single data type (either graphs or sequences), leaving multi-source fusion and reasoning mechanisms underdeveloped.</p> <hr> <h2 id="2-limitations-of-llms-for-this-problem">2. Limitations of LLMs for This Problem</h2> <ul> <li> <strong>Training data lacks structure-driven tasks</strong>: LLMs haven’t been pretrained on graph-specific or sequence-inductive tasks</li> <li> <strong>Prompt + tool integration is limited</strong>: While RAG or tools like StructGPT can assist, they still depend on external structural models</li> <li> <strong>No native structured reasoning</strong>: Chain-of-thought prompting is not well suited for deeply structured contexts; specialized structural reasoning strategies are needed</li> </ul> <p>This suggests exploring a <strong>biologically inspired architecture</strong> that mimics the brain’s ways of processing structured inputs to enhance LLM capabilities for complex reasoning.</p> <hr> <h2 id="3-how-the-human-brain-tackles-it-four-structural-mechanisms">3. How the Human Brain Tackles It: Four Structural Mechanisms</h2> <h3 id="31-brain-richclub-network-long-range-hub-organization">3.1 Brain Rich‑Club Network (Long-range hub organization)</h3> <p>The brain features a network of “rich-club” nodes—highly interconnected hub regions that integrate information across functional zones and support high-level cognition.</p> <h3 id="32-structured-slots-sequence-memory--cognitive-map-integration">3.2 Structured Slots (Sequence Memory + Cognitive Map Integration)</h3> <p>Through prefrontal–hippocampal mechanisms, the brain unifies sequence memory (state-action transitions) and cognitive maps (graph structures). Whittington et al. (2025) propose the <strong>structured slots</strong> model to explain this integration.</p> <h3 id="33-episodic-buffer-working-memory-integration-mechanism">3.3 Episodic Buffer (Working Memory Integration Mechanism)</h3> <p>According to Baddeley’s working memory model, the brain uses an <strong>episodic buffer</strong> to fuse visual, language, and structural information into a coherent contextual representation.</p> <h3 id="34-predictive-coding-error-driven-learning-mechanism">3.4 Predictive Coding (Error-driven Learning Mechanism)</h3> <p>The brain employs top-down predictions and bottom-up error signals in a loop, iteratively updating its internal model, enabling stable structure perception and semantic fusion.</p> <hr> <h2 id="4-biologically-inspired-modular-design-python--pytorch-implementation">4. Biologically Inspired Modular Design (Python / PyTorch Implementation)</h2> <h3 id="system-architecture-overview">System Architecture Overview</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Graph Module (rich‑club graph)
↓
Slots Module (structured slots)
↓
Episodic Buffer (structure + semantic fusion)
↓
Predictive Coding Layer (prediction + SGD learning)

</code></pre></div></div> <p>Each module corresponds to one of the brain-inspired mechanisms and works together to facilitate structured data understanding and semantic integration.</p> <hr> <h3 id="41-graph-module-rich-club-structure--gnn-implementation">4.1 Graph Module: rich-club structure + GNN implementation</h3> <ul> <li>Build a central dense subgraph (rich-club) plus two sparse subgraphs (each for a subtasks) and interconnect them</li> <li>Use NetworkX to generate the graph, and PyTorch Geometric’s <code class="language-plaintext highlighter-rouge">GCNConv</code> to extract node embeddings</li> <li>Aggregate embeddings of the central nodes to produce a rich-club representation</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">from_networkx</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="bp">...</span>
</code></pre></div></div> <hr> <h3 id="42-slots-module-structured-slots-implementation">4.2 Slots Module: Structured Slots Implementation</h3> <ul> <li>Use a set of trainable slots to simulate prefrontal activity slots</li> <li>Apply attention to read relevant slot states and write updates to them</li> <li>Train the module so it encodes both sequence memory and cognitive map representations</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SlotsModule</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(...):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="n">slots</span><span class="p">)</span> <span class="o">@</span> <span class="n">key</span><span class="p">)</span>
        <span class="n">slot_read</span> <span class="o">=</span> <span class="n">weighted</span> <span class="nb">sum</span> <span class="n">over</span> <span class="n">slots</span>
        <span class="n">new_slot</span> <span class="o">=</span> <span class="n">slot_read</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">slot_read</span><span class="p">,</span> <span class="n">new_slot</span>
</code></pre></div></div> <hr> <h3 id="43-episodic-buffer-multimodal-structure--semantic-fusion">4.3 Episodic Buffer: Multimodal Structure + Semantic Fusion</h3> <ul> <li>Concatenate the rich-club representation from GraphModule with the slot_read representation</li> <li>Use a linear projection layer to produce a fused contextual embedding</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">EpisodicBuffer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(...):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">graph_repr</span><span class="p">,</span> <span class="n">slot_repr</span><span class="p">):</span>
        <span class="n">fused</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">graph_repr</span><span class="p">,</span> <span class="n">slot_repr</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">combine</span><span class="p">(</span><span class="n">fused</span><span class="p">))</span>
</code></pre></div></div> <hr> <h3 id="44-predictive-coding-layer-error-driven-learning">4.4 Predictive Coding Layer: Error-driven learning</h3> <ul> <li>Build a layer <code class="language-plaintext highlighter-rouge">predict(state)</code> to predict the next state</li> <li>Compute error <code class="language-plaintext highlighter-rouge">state - pred</code> as the training loss</li> <li>Use SGD to update parameters and simulate predictive coding dynamics</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PredCodeLayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(...):</span>
        <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">state</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span> <span class="o">-</span> <span class="n">pred</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">err</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">pred</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">err</span>
</code></pre></div></div> <hr> <h2 id="5-integrated-example-pseudocode-structure">5. Integrated Example Pseudocode Structure</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inputs include: graph data, behavior sequence key, expected next slot state, etc.
</span>
<span class="n">h</span><span class="p">,</span> <span class="n">center_repr</span> <span class="o">=</span> <span class="nf">graph_module</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">slot_read</span><span class="p">,</span> <span class="n">new_slot</span><span class="p">,</span> <span class="n">att</span> <span class="o">=</span> <span class="nf">slots_module</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">buffer_state</span> <span class="o">=</span> <span class="nf">episodic_buffer</span><span class="p">(</span><span class="n">center_repr</span><span class="p">,</span> <span class="n">slot_read</span><span class="p">)</span>
<span class="n">pred</span><span class="p">,</span> <span class="n">loss_pc</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="nf">predcode_layer</span><span class="p">(</span><span class="n">buffer_state</span><span class="p">)</span>
<span class="n">loss_slot</span> <span class="o">=</span> <span class="bp">...</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_pc</span> <span class="o">+</span> <span class="n">loss_slot</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <p>This design is intended to <strong>simulate rich-club architecture, structured slots, episodic buffer-based integration, and predictive-coding-based learning</strong>, all trained with SGD.</p> <hr> <h2 id="6-future-outlook">6. Future Outlook</h2> <ul> <li>Starting from <strong>LLM limitations in structured data understanding</strong>, we draw inspiration from four brain mechanisms</li> <li>Each module is mapped to a neurally plausible function and implemented in PyTorch</li> <li>The integrated system uses predictive coding + SGD to simulate bio-inspired learning and semantic-structure fusion</li> <li>It can be extended to downstream risk-control tasks: graph-based account network reasoning, slot-based behavior sequence storage, buffer-level multimodal fusion, and predictive coding for structure-aware reasoning</li> <li>If this paradigm shows promising results on specific tasks, it may further motivate <strong>bio-inspired research directions</strong> </li> </ul> <hr> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yuechun (Ethan) Gu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>